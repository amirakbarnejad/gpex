{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import loadmnist\n",
    "from loadmnist import *\n",
    "list_pathstoadd = [\n",
    "    \"../../\"\n",
    "]\n",
    "for path in list_pathstoadd:\n",
    "    if(path not in sys.path):\n",
    "        sys.path.append(path)\n",
    "#import generalGPmodule\n",
    "import localsrc_mnistdemo\n",
    "from localsrc_mnistdemo import *\n",
    "import gpex\n",
    "import resnetformnist\n",
    "from resnetformnist import *\n",
    "from gpex.kernelmappings.image import Resnet50BackboneKernelDivideAvgPool\n",
    "tfm_denormalize = loadmnist.ImgnetDenormalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings ====\n",
    "idx_trainingbatch = 1\n",
    "flag_enabledataaugmentation = True\n",
    "fname_gpmodel = os.path.join(\n",
    "    \"..\",\n",
    "    \"..\",\n",
    "    \"Material_PaperResults\",\n",
    "    \"Models\",\n",
    "    \"ExplainClassifier\",\n",
    "    \"mnist_classification.pt\"\n",
    ")\n",
    "\n",
    "#\"../../Material_PaperResults/Models/ExplainClassifier/cifar10.pt\"\n",
    "flag_loadalltraining = True\n",
    "int_mode_modulekernel = 16\n",
    "flag_train_memefficient, memefficeint_heads_in_compgraph = False, None\n",
    "du_per_class = 20\n",
    "int_exposedclass = None\n",
    "idx_split = 0\n",
    "dim_wideoutput = 1024\n",
    "flag_loadalltraining = False\n",
    "num_classes = 10\n",
    "batchsize = 10\n",
    "flag_efficient = True\n",
    "flag_detachcovpvn = True\n",
    "flag_controlvariate = True\n",
    "flag_setcovtoOne = False\n",
    "int_mode_controlvariate = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath_ds = os.path.join(\n",
    "    \"..\",\n",
    "    \"..\",\n",
    "    \"Material_PaperResults\",\n",
    "    \"Datasets\",\n",
    "    \"MNIST\"\n",
    ")\n",
    "\n",
    "ds_train = MNISTDataset(\n",
    "    rootdir = rootpath_ds,\n",
    "    str_trainortest = \"train\",\n",
    "    flag_enabledataaugmentation = False\n",
    ")\n",
    "ds_inducing = MNISTDataset(\n",
    "    rootdir = rootpath_ds,\n",
    "    str_trainortest = \"train\",\n",
    "    flag_enabledataaugmentation = False\n",
    ")\n",
    "ds_test = MNISTDataset(\n",
    "    rootdir = rootpath_ds,\n",
    "    str_trainortest = \"test\",\n",
    "    flag_enabledataaugmentation = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=batchsize,\n",
    "                      shuffle=True, num_workers=0)\n",
    "dl_inducing = DataLoader(ds_inducing, batch_size=batchsize,\n",
    "                          shuffle=True, num_workers=0)\n",
    "dl_test = DataLoader(ds_test, batch_size=batchsize,\n",
    "                     shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MainModule(\n",
    "    dim_wideoutput=dim_wideoutput,\n",
    "    num_classes = num_classes,\n",
    "    device = device,\n",
    "    ds_inducing = ds_inducing,\n",
    "    dl_recurring = dl_inducing,\n",
    "    dl_nonrecurring = dl_train,\n",
    "    dl_test = dl_test,\n",
    "    batchsize = batchsize\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "print(\"Model was created in {}.\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.n_subsampleminibatch = 2\n",
    "gpexmodule = gpex.GPEXModule(\n",
    "    module_rawmodule = model,\n",
    "    size_recurringdataset = len(ds_inducing),\n",
    "    device = device,\n",
    "    func_mainmodule_to_moduletobecomeGP = model.func_mainmodule_to_moduletobecomeGP, \n",
    "    func_feed_noise_minibatch = model.func_feed_noise_minibatch,\n",
    "    func_feed_inducing_minibatch = model.func_feed_inducing_minibatch,\n",
    "    func_feed_nonrecurring_minibatch = model.func_feed_nonrecurring_minibatch,\n",
    "    func_feed_test_minibatch = model.func_feed_test_minibatch,\n",
    "    func_get_indices_lastrecurringinstances = model.func_get_indices_lastrecurringinstances,\n",
    "    func_get_modulef1 = model.func_get_modulef1\n",
    ")\n",
    "gpexmodule.sigma2_GP = 1.0 #TODO:check\n",
    "gpexmodule.to(device)\n",
    "print(\"gpmodel was created on {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model from checkpoint ====\n",
    "gpexmodule.load_state_dict(\n",
    "    torch.load(\n",
    "        fname_gpmodel\n",
    "     ),\n",
    "    strict = True\n",
    ")\n",
    "gpexmodule.train()\n",
    "gpexmodule.to(device)\n",
    "gpexmodule.renew_precomputed_XTX()\n",
    "print(\"gpmodel was loaded from checkpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check if g(.) and GP path match on test instances ====\n",
    "gpexmodule.renew_precomputed_XTX()\n",
    "list_outputgpoutputg = gpexmodule.checkequal_GPout_ANNout_ontest(10)\n",
    "for n in range(len(list_outputgpoutputg)):\n",
    "    a = list_outputgpoutputg[n][0]\n",
    "    b = list_outputgpoutputg[n][1]\n",
    "    \n",
    "    \n",
    "    min_ab = min(np.min(a), np.min(b))\n",
    "    max_ab = max(np.max(a), np.max(b))\n",
    "        \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(np.round(a, 2), vmin=min_ab, vmax=max_ab, aspect=\"auto\"); plt.colorbar()\n",
    "    plt.title(\"GPs output\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(np.round(b, 2), vmin=min_ab, vmax=max_ab, aspect=\"auto\"); plt.colorbar()\n",
    "    plt.title(\"ANN output\")\n",
    "    plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Correlation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpex.evaluation\n",
    "from gpex.evaluation import GPdiffANN_ontorchdl\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from scipy import stats\n",
    "\n",
    "output, dict_gt = GPdiffANN_ontorchdl(\n",
    "    gpmodel = gpexmodule,\n",
    "    dl_input = dl_test,\n",
    "    input_device = device\n",
    ")\n",
    "\n",
    "np_gpann = np.array(\n",
    "    [output[k] for k in output.keys()]\n",
    ")\n",
    "np_gt = np.array([dict_gt[k] for k in output.keys()])\n",
    "\n",
    "numclasses = int(np_gpann.shape[1]/2)\n",
    "list_correlation = []\n",
    "for c in range(numclasses):\n",
    "    list_correlation.append(\n",
    "        stats.pearsonr(np_gpann[:, c], np_gpann[:, c+numclasses])[0]\n",
    "    )\n",
    "print(\"list correlation = {}\".format(np.round(list_correlation, 3)))\n",
    "gp_labels = np.argmax(np_gpann[:, 0:numclasses], 1)\n",
    "ann_labels = np.argmax(np_gpann[:, numclasses::], 1)\n",
    "acc_ann = np.sum(ann_labels == np_gt)/np_gpann.shape[0]\n",
    "acc_gp = np.sum(gp_labels == np_gt)/np_gpann.shape[0]\n",
    "print(\"Acuuray of ANN {}\".format(acc_ann))\n",
    "print(\"   Acuuracy of GP {}\".format(acc_gp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depict the Correlation Scatters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "np_gp = np_gpann[:,0:num_classes]\n",
    "np_ann = np_gpann[:,num_classes::]\n",
    "np_gp_softmax = softmax(np_gp, 1)\n",
    "np_ann_softmax = softmax(np_ann, 1)\n",
    "\n",
    "list_disaggrement = (np.argmax(np_gp, 1) != np.argmax(np_ann, 1)).tolist()\n",
    "list_c = [0,0,0,0.2] #[[1,0,0,1] if(u==True) else [0,0,0,0.05] for u in list_disaggrement]\n",
    "count_plotted = 0\n",
    "for c in range(num_classes):\n",
    "    plt.ioff()\n",
    "    plt.figure()\n",
    "    plt.scatter(np_gp[:,c], np_ann[:,c], c=np.array(list_c), marker='o', facecolors='none')\n",
    "    plt.axis(\"equal\")\n",
    "    plt.xlabel(\"GP output (head {})\".format(c+1), fontsize=18)\n",
    "    plt.ylabel(\"ANN output (head {})\".format(c+1), fontsize=18)\n",
    "    plt.title(\"Scatter for output head {}\".format(count_plotted+1), fontsize=20)\n",
    "    count_plotted += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_NNs(model_input, ds_input, input_device):\n",
    "    model_input.eval()\n",
    "    toret = []\n",
    "    list_gty = []\n",
    "    list_uncertainty = []\n",
    "    list_similarities = []\n",
    "    list_x, list_y = [], []\n",
    "    list_output_g = []\n",
    "    for n in range(len(ds_input)):\n",
    "        print(\" instance {} from {}\".format(n, len(ds_input)), end='\\r')\n",
    "        x, y, _ = ds_input[n]\n",
    "        output, uncertainty, output_similarities = \\\n",
    "                model_input.testingtime_forward(x.unsqueeze(0).to(input_device), y, n)\n",
    "        #print(\"output_similaritites.shape = {}\".format(output_similarities.shape))\n",
    "        output = output[0]\n",
    "        toret.append(output.detach().cpu().numpy())\n",
    "        list_gty.append(y)\n",
    "        list_uncertainty.append(uncertainty)\n",
    "        list_similarities.append(output_similarities.detach().cpu().numpy())\n",
    "        list_x.append(x); list_y.append(y)\n",
    "        #feed the model to g(.) ====\n",
    "        output_g, _, _ = \\\n",
    "                model_input.module_rawmodule(x.unsqueeze(0).to(input_device), y, n)\n",
    "        list_output_g.append(output_g.detach().cpu().numpy().flatten().tolist())\n",
    "\n",
    "    print(\"\\n\")\n",
    "    toret = np.array(toret)\n",
    "    toret = toret[:,0,:]\n",
    "    output_g = np.array(list_output_g)\n",
    "    print(output_g.shape)\n",
    "    model_input.train()\n",
    "    return toret, list_gty, list_uncertainty, list_similarities, list_x, list_y, output_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_retval_inspectmodel = [inspect_NNs(gpexmodule, ds_test, device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# the two instances for the introduction of the paper ====\n",
    "#%%capture\n",
    "m = 10\n",
    "list_shownn = [10, 393, 388, 221, 82, 77, 18, 789, 670, 610, 447, 33, 6]\n",
    "for n in list_shownn:\n",
    "    \n",
    "    plt.figure(figsize=((m+2)*10, 2*10))\n",
    "    count_subplot = 1\n",
    "    \n",
    "    _, list_gty, _, _, list_x, list_y, _ = list_retval_inspectmodel[0]\n",
    "    x, y = list_x[n], list_y[n]\n",
    "    \n",
    "    \n",
    "    str_subfolder = \"\"\n",
    "    idx_model = 0 #for idx_model in range(len(list_retval_inspectmodel)):\n",
    "    list_predy, list_gty, list_uncertainty, list_similarities, _, _, output_g = \\\n",
    "                        list_retval_inspectmodel[idx_model]\n",
    "    np_argmax_list_predyn = np.argmax(output_g[n])\n",
    "    if(np_argmax_list_predyn == list_gty[n]):\n",
    "        str_subfolder = str_subfolder + \"True\"\n",
    "    else:\n",
    "        str_subfolder = str_subfolder + \"False\"\n",
    "    kn = list_similarities[n][np_argmax_list_predyn, :].flatten()\n",
    "    idx_similars = np.argsort(-kn).tolist()[0:m]\n",
    "    plt.ioff()\n",
    "    plt.subplot(1, 1*(m+1), count_subplot); count_subplot+=1;\n",
    "    plt.imshow(tfm_denormalize(x).cpu().numpy().transpose(1,2,0))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    for count_similars in range(len(idx_similars)):\n",
    "        plt.subplot(1, 1*(m+1), count_subplot); count_subplot+=1;\n",
    "        plt.imshow(\n",
    "          tfm_denormalize(\n",
    "                  ds_inducing[idx_similars[count_similars]][0]\n",
    "              ).cpu().numpy().transpose(1,2,0),\n",
    "        )\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
